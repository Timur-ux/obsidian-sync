Дословный перевод -- мягкое максимальное. Де-факто это функция, которая преобразует вектор значений в вектор вероятностей этих значений.

Её плюсом является то, что если в векторе значений имеется несколько с примерно равными максимальному значению, то вероятности соответствующих значений будут почти равны.

[[Softmax]] можно реализовать следующим образом:
* Для каждого значения вектора $x_k$ из исходного вектора вычисляем $e^{x_k}$, и считаем сумму всех экспонент $S$.
* Потом вместо элемента $x_k$ записываем 
 $$
 \frac{e^{x_k}}{S} = \frac{e^{x_k}}{\sum\limits^K_{i=1}e^{x_i}}
 $$
Т.е. мы считаем экспоненту каждого значения и нормализуем его по всем значениям.

Запрограммировать это можно следующим образом:
```C++
void softmax(std::vector<double> & values) {
	double S = 0;
	for(double val : values)
		S += std::exp(val);
	for(double & val : values)
		val = std::exp(val) / S;
}
```

[[LLM]] [[De-embedding]] [[Softmax]]