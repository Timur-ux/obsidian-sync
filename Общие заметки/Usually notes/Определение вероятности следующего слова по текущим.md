Закодировав слова через one-hot кодирование мы можем представлять вероятности следующих слов в виде нормализованного вектора вероятностей, перемножив скалярно которые, мы можем получить следующего слова, как элемент результирующего вектора с максимальным значением.

Расширением этого на несколько слов может быть матричное перемножение матрицы из входных слов и матрицы соответствующих вероятностей

[[ML]] [[LLM]] [[one-hot encoding]]