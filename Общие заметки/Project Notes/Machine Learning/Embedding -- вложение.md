One-hot кодирование приводит к тому, что хранение N слов требует O(N^2)
памяти, что не есть гут. Так вот идея embedding'а заключается в том, чтобы спроектировать N-мерные вектора в пространство с большим количеством измерений. Например, в точки на плоскости, если пространство, на которое происходит проецирование -- двумерное. Дополнительно на вложение накладывается требование, чтобы слова, имеющие близкий смысл, были расположены поблизости и в новом пространстве.

Для популярных языков, можно скачать уже обученную модель embedding'а,
но, конечно же, как и любой другой элемент [[LLM]], данную модель можно обучить.

Идея реализации [[embedding]]: [[Идея реализации embedding]]

Важно, чтобы размерность проективного пространства была степенью двойки, т.к. это нам понадобится в варианте реализации следующего этапа трансформации -- [[Position encoding -- вариант реализации]]

[[LLM]]  [[embedding]]  [[one-hot encoding]]